{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zaimportowanie potrzebnych bibliotek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.01. Wczytanie bazy danych\n",
    "dataset = pd.read_csv('Loan_Default.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.02. Sprawdzenie liczby kolumn, liczby wierszy, nazw kolumn\n",
    "print(f\"- (Wiersze, kolumny) = {dataset.shape}\")\n",
    "print(f\"- Nazwy kolumn = \\n{dataset.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.03. Przejrzenie kilku pierwszych i kilku ostatnich wierszy bazy\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.03. Przejrzenie kilku pierwszych i kilku ostatnich wierszy bazy\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.04. Sprawdzenie informacji dotyczących poszczególnych kolumn\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.05. Zrobienie zestawienia tego, w jakich kolumnach jest najwięcej wartości Null \n",
    "total_rows = len(dataset)\n",
    "null_report = pd.DataFrame({\n",
    "    'Null Values': dataset.isnull().sum(),\n",
    "    'Percent Missing': (round(dataset.isnull().sum() / total_rows, 5)) * 100\n",
    "})\n",
    "null_report_sorted = null_report.sort_values(by='Percent Missing', ascending=False)\n",
    "print(null_report_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.06. Ustalenie, ile wierszy musielibyśmy wyrzucić, gdybyśmy wyrzucali każdy z min. 1 pustym rekordem\n",
    "dataset2 = dataset.dropna()\n",
    "print(dataset2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.07. Uzupełnienie pustych rekordów średnimi arytmetycznymi lub modami z danych kolumn\n",
    "for column in dataset.columns:\n",
    "    if dataset[column].dtype == 'object':\n",
    "        most_frequent = dataset[column].mode()[0]\n",
    "        dataset[column].fillna(most_frequent, inplace=True)\n",
    "    else:\n",
    "        mean_value = dataset[column].mean()\n",
    "        dataset[column].fillna(mean_value, inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.08. Sprawdzenie, czy mamy zduplikowane wiersze w bazie danych i jeśli tak, to jakie\n",
    "duplicates_count = dataset.duplicated().sum()\n",
    "print(f\"Liczba zduplikowanych wierszy: {duplicates_count}\")\n",
    "if duplicates_count>0: print(dataset[dataset.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.09. Sprawdzenie, ile mamy unikalnych wartości w każdej z kolumn\n",
    "unique_values = dataset.nunique()\n",
    "unique_values_text = \"\\n\".join([f\"{col} - {count}\" for col, count in unique_values.items()])\n",
    "unique_values_text_sorted = unique_values.sort_values()\n",
    "print(unique_values_text_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.10. Sprawdzenie, jakie mamy unikalne wartości, dla kolumn z <10 unikalnymi wartościami\n",
    "unique_values = {}\n",
    "for column in dataset.columns:\n",
    "    if dataset[column].nunique() < 10:\n",
    "        unique_values[column] = dataset[column].unique() \n",
    "for column, values in unique_values.items():\n",
    "        print(f'Kolumna: {column}')\n",
    "        for value in values: print(f'{value}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.11. Przetworzenie bazy danych - \n",
    "# wyrzucenie 'year', modyfikacja 'age' i modyfikacja OBJECT na INT gdy mamy malo unikatow w danej kolumnie\n",
    "\n",
    "#dataset = dataset.drop(columns=['year'])\n",
    "\n",
    "dataset['age'] = dataset['age'].replace('<25', 20)\n",
    "dataset['age'] = dataset['age'].replace('25-34', 30)\n",
    "dataset['age'] = dataset['age'].replace('35-44', 40)\n",
    "dataset['age'] = dataset['age'].replace('45-54', 50)\n",
    "dataset['age'] = dataset['age'].replace('55-64', 60)\n",
    "dataset['age'] = dataset['age'].replace('65-74', 70)\n",
    "dataset['age'] = dataset['age'].replace('>74', 80)\n",
    "dataset['age'] = dataset['age'].replace(np.nan, dataset['age'].mode()[0])\n",
    "\n",
    "# 1.12 Tabela zmian rekordów OBJECT na rekordy INT\n",
    "dataset['loan_limit'] = dataset['loan_limit'].replace('cf', 1)\n",
    "dataset['loan_limit'] = dataset['loan_limit'].replace('ncf', 0)\n",
    "dataset['Gender'] = dataset['Gender'].replace('Sex Not Available', 9)\n",
    "dataset['Gender'] = dataset['Gender'].replace('Male', 2)\n",
    "dataset['Gender'] = dataset['Gender'].replace('Female', 3)\n",
    "dataset['Gender'] = dataset['Gender'].replace('Joint', 5)\n",
    "dataset['approv_in_adv'] = dataset['approv_in_adv'].replace('pre', 1)\n",
    "dataset['approv_in_adv'] = dataset['approv_in_adv'].replace('nopre', 0)\n",
    "dataset['loan_type'] = dataset['loan_type'].replace('type1', 1)\n",
    "dataset['loan_type'] = dataset['loan_type'].replace('type2', 2)\n",
    "dataset['loan_type'] = dataset['loan_type'].replace('type3', 3)\n",
    "dataset['loan_purpose'] = dataset['loan_purpose'].replace('p1', 1)\n",
    "dataset['loan_purpose'] = dataset['loan_purpose'].replace('p2', 2)\n",
    "dataset['loan_purpose'] = dataset['loan_purpose'].replace('p3', 3)\n",
    "dataset['loan_purpose'] = dataset['loan_purpose'].replace('p4', 4)\n",
    "dataset['Credit_Worthiness'] = dataset['Credit_Worthiness'].replace('l1', 1)\n",
    "dataset['Credit_Worthiness'] = dataset['Credit_Worthiness'].replace('l2', 2)\n",
    "dataset['open_credit'] = dataset['open_credit'].replace('opc', 1)\n",
    "dataset['open_credit'] = dataset['open_credit'].replace('nopc', 0)\n",
    "dataset['business_or_commercial'] = dataset['business_or_commercial'].replace('b/c', 1)\n",
    "dataset['business_or_commercial'] = dataset['business_or_commercial'].replace('nob/c', 0)\n",
    "dataset['Neg_ammortization'] = dataset['Neg_ammortization'].replace('neg_amm', 1)\n",
    "dataset['Neg_ammortization'] = dataset['Neg_ammortization'].replace('not_neg', 0)\n",
    "dataset['interest_only'] = dataset['interest_only'].replace('int_only', 1)\n",
    "dataset['interest_only'] = dataset['interest_only'].replace('not_int', 0)\n",
    "dataset['lump_sum_payment'] = dataset['lump_sum_payment'].replace('lpsm', 1)\n",
    "dataset['lump_sum_payment'] = dataset['lump_sum_payment'].replace('not_lpsm', 0)\n",
    "dataset['construction_type'] = dataset['construction_type'].replace('sb', 1)\n",
    "dataset['construction_type'] = dataset['construction_type'].replace('mh', 2)\n",
    "dataset['occupancy_type'] = dataset['occupancy_type'].replace('pr', 1)\n",
    "dataset['occupancy_type'] = dataset['occupancy_type'].replace('sr', 2)\n",
    "dataset['occupancy_type'] = dataset['occupancy_type'].replace('ir', 3)\n",
    "dataset['Secured_by'] = dataset['Secured_by'].replace('home', 1)\n",
    "dataset['Secured_by'] = dataset['Secured_by'].replace('land', 2)\n",
    "dataset['total_units'] = dataset['total_units'].replace('1U', 1)\n",
    "dataset['total_units'] = dataset['total_units'].replace('2U', 2)\n",
    "dataset['total_units'] = dataset['total_units'].replace('3U', 3)\n",
    "dataset['total_units'] = dataset['total_units'].replace('4U', 4)\n",
    "dataset['credit_type'] = dataset['credit_type'].replace('EXP', 1)\n",
    "dataset['credit_type'] = dataset['credit_type'].replace('EQUI', 2)\n",
    "dataset['credit_type'] = dataset['credit_type'].replace('CRIF', 3)\n",
    "dataset['credit_type'] = dataset['credit_type'].replace('CIB', 4)\n",
    "dataset['co-applicant_credit_type'] = dataset['co-applicant_credit_type'].replace('EXP', 1)\n",
    "dataset['co-applicant_credit_type'] = dataset['co-applicant_credit_type'].replace('CIB', 4)\n",
    "dataset['submission_of_application'] = dataset['submission_of_application'].replace('to_inst', 1)\n",
    "dataset['submission_of_application'] = dataset['submission_of_application'].replace('not_inst', 0)\n",
    "dataset['Region'] = dataset['Region'].replace('south', 1)\n",
    "dataset['Region'] = dataset['Region'].replace('North', 2)\n",
    "dataset['Region'] = dataset['Region'].replace('central', 3)\n",
    "dataset['Region'] = dataset['Region'].replace('North-East', 4)\n",
    "dataset['Security_Type'] = dataset['Security_Type'].replace('direct', 1)\n",
    "dataset['Security_Type'] = dataset['Security_Type'].replace('Indriect', 0)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.13 Sprawdzenie informacji dotyczących poszczególnych kolumn - ponownie\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.14 Sprawdzenie, czy mamy w bazie danych wartosci z niepoprawnego zakresu lub outliers\n",
    "# 1.15 Uwagi i przemyslenia dotyczace sprawdzania czy cos jest z niepoprawnego zakresu lub jest outlierem\n",
    "# 1.16 Regula interkwartylowa do sprawdzania czy cos jest outlierem\n",
    "# 1.17 Strategia radzenia sobie z odstajacymi wartosciami - nic nie robic z nimi\n",
    "\n",
    "valid_ranges = {\n",
    "    'loan_amount': (0, None),\n",
    "    'rate_of_interest': (0, 100),\n",
    "    'Upfront_charges': (0, None),\n",
    "    'term': (0, None),\n",
    "    'property_value': (0, None),\n",
    "    'income': (0, None),\n",
    "    'Credit_Score': (500, 900),\n",
    "    'LTV': (0, None),\n",
    "    'dtir1': (0, 100)\n",
    "}\n",
    "\n",
    "def analyze_column(col, valid_range):\n",
    "    invalid_count = 0\n",
    "    outlier_count = 0\n",
    "    if col.dtype in ['int64', 'float64']:\n",
    "        if valid_range:\n",
    "            if valid_range[1] is not None:\n",
    "                invalid_count = ((col < valid_range[0]) | (col > valid_range[1])).sum()\n",
    "            else:\n",
    "                invalid_count = (col < valid_range[0]).sum()\n",
    "        Q1 = col.quantile(0.25)\n",
    "        Q3 = col.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outlier_count = ((col < lower_bound) | (col > upper_bound)).sum()\n",
    "    return invalid_count, outlier_count\n",
    "\n",
    "results = {}\n",
    "for column in dataset.columns:\n",
    "    if column in valid_ranges:\n",
    "        valid_range = valid_ranges[column]\n",
    "        invalid, outliers = analyze_column(dataset[column], valid_range)\n",
    "        results[column] = {\n",
    "            'Invalid Count': invalid,\n",
    "            'Outlier Count': outliers,\n",
    "            'Outlier Percent': (outliers/(len(dataset[f'{column}'])))*100\n",
    "        }\n",
    "        \n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.18 Zapisanie przetworzonej bazy danych\n",
    "dataset.to_csv('DATA.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
